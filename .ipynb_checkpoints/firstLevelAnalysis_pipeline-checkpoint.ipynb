{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "#nilearn imports\n",
    "from nilearn import plotting, image, interfaces\n",
    "from nilearn.image import mean_img\n",
    "from nilearn.plotting import plot_anat, plot_img, plot_stat_map, show, plot_design_matrix\n",
    "from nilearn.glm import threshold_stats_img\n",
    "from nilearn.glm.first_level import FirstLevelModel, make_first_level_design_matrix\n",
    "from nilearn.reporting import get_clusters_table\n",
    "import nilearn\n",
    "\n",
    "#sklearn imports\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get first level weights for the runs\n",
    "#possible task types include colorWheel or sameDifferent \n",
    "\n",
    "def extract_beta_weights(subject_id = None, task_type = 'colorwheel',  n_runs=1):\n",
    "    \"\"\"\n",
    "    extract_beta_weights runs first level analysis on each of the subjects, \n",
    "    storing their weights for each task type and run in a dictionary.\n",
    "\n",
    "    subject_id: subject ID \n",
    "    task_type: colorWheel or sameDifferent \n",
    "    n_runs: max 4 runs, use less when testing\n",
    "    \"\"\"\n",
    "    #parameters\n",
    "    tr = 2.0 \n",
    "\n",
    "    # choose appropriate hrf model\n",
    "    hrf_model = \"spm + derivative\"\n",
    "    smoothing_fwhm = 6 # gaussian kernel width (in mm)\n",
    "    drift_model = None  # cosine drift terms already in confounds\n",
    "    high_pass=None,  # drift terms equivalent to high-pass filter\n",
    "    n_jobs=-2,  # use all-1 available CPUs\n",
    "\n",
    "    # choose whatever confounds you want to include\n",
    "    interested_confounds = [\"rot_x\", \"trans_x\", \"white_matter\", \"csf\"]\n",
    "\n",
    "    for num_run in range(n_runs):\n",
    "        preproc_path = f\"~/teams/a05/group_1_data/fmriprep/sub-{subject_id}/func/sub-{subject_id}_task-{task_type}**{num_run + 1}**desc-preproc_bold.nii.gz\"\n",
    "        events_path = f\"~/teams/a05/group_1_data/fmriprep/events/sub-{subject_id}_task-{task_type}_acq-multiband_run-{num_run+1}_events.tsv\"\n",
    "        \n",
    "        #load subject nii files\n",
    "        run_img = image.load_img(preproc_path)\n",
    "\n",
    "        #load the event file for the run\n",
    "        events = pd.read_csv(events_path, sep=\"\\t\", \n",
    "                            usecols=[\"onset\", \"duration\"]).assign(\n",
    "                            trial_type=\"colorwheel\")\n",
    "\n",
    "        #include confounds\n",
    "        confounds = interfaces.fmriprep.load_confounds_strategy(\n",
    "            preproc_path, denoise_strategy=\"simple\")[0]#[interested_confounds]\n",
    "\n",
    "        #run the first level model\n",
    "        fmri_glm = FirstLevelModel(\n",
    "            t_r=tr,\n",
    "            hrf_model=hrf_model,\n",
    "            smoothing_fwhm=smoothing_fwhm,\n",
    "            drift_model=drift_model,\n",
    "            minimize_memory=False   \n",
    "        )\n",
    "\n",
    "        fmri_glm = fmri_glm.fit(run_img, events, confounds)\n",
    "\n",
    "        #design matrix = task (convolved with HRF) + confounds\n",
    "        design_matrix = fmri_glm.design_matrices_[0]\n",
    "\n",
    "        # map of parameter estimates / beta weights\n",
    "        # this is the 'feature' map to use in classification\n",
    "        beta_weights = fmri_glm.compute_contrast(task_type, output_type=\"effect_size\")\n",
    "    return beta_weights\n",
    "\n",
    "extract_beta_weights(103, 'samedifferent')['samedifferent']['run_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # SVM classifier\n",
    "    svm_model = SVC(kernel='linear')\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "\n",
    "    # Evaluate performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Model Accuracy: \" + str(accuracy))\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    show()\n",
    "\n",
    "    return svm_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
