{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#nilearn imports\n",
    "from nilearn import plotting, image, interfaces\n",
    "from nilearn.image import mean_img\n",
    "from nilearn.plotting import plot_anat, plot_img, plot_stat_map, show, plot_design_matrix\n",
    "from nilearn.glm import threshold_stats_img\n",
    "from nilearn.glm.first_level import FirstLevelModel, make_first_level_design_matrix\n",
    "from nilearn.reporting import get_clusters_table\n",
    "import nilearn\n",
    "\n",
    "#sklearn imports\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "DimensionError",
     "evalue": "Input data has incompatible dimensionality: Expected dimension is 4D and you provided a list of 4D images (5D). See https://nilearn.github.io/stable/manipulating_images/input_output.html.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDimensionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m         beta_weights \u001b[38;5;241m=\u001b[39m fmri_glm\u001b[38;5;241m.\u001b[39mcompute_contrast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolorwheel\u001b[39m\u001b[38;5;124m\"\u001b[39m, output_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meffect_size\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m beta_weights\n\u001b[0;32m---> 61\u001b[0m \u001b[43mextract_beta_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m103\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msamedifferent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msamedifferent\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun_1\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[15], line 31\u001b[0m, in \u001b[0;36mextract_beta_weights\u001b[0;34m(subject_id, task_type, n_runs)\u001b[0m\n\u001b[1;32m     28\u001b[0m events_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m~/teams/a05/group_1_data/fmriprep/sub-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubject_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/func/sub-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubject_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_task-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m*run-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_run\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_events.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#load subject nii files\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m run_img \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreproc_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#load the event file for the run\u001b[39;00m\n\u001b[1;32m     34\u001b[0m events \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(events_path, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     35\u001b[0m                     usecols\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39massign(\n\u001b[1;32m     36\u001b[0m                     trial_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolorwheel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/nilearn/image/image.py:1392\u001b[0m, in \u001b[0;36mload_img\u001b[0;34m(img, wildcards, dtype)\u001b[0m\n\u001b[1;32m   1355\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_img\u001b[39m(img, wildcards\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1356\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a Niimg-like object from filenames or list of filenames.\u001b[39;00m\n\u001b[1;32m   1357\u001b[0m \n\u001b[1;32m   1358\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 0.2.5\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \n\u001b[1;32m   1391\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcheck_niimg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwildcards\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwildcards\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/nilearn/_utils/niimg_conversions.py:310\u001b[0m, in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_iterator:\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m iter_check_niimg(\n\u001b[1;32m    308\u001b[0m             niimg, ensure_ndim\u001b[38;5;241m=\u001b[39mensure_ndim, dtype\u001b[38;5;241m=\u001b[39mdtype\n\u001b[1;32m    309\u001b[0m         )\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mni\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat_imgs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mniimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_ndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# Otherwise, it should be a filename or a SpatialImage, we load it\u001b[39;00m\n\u001b[1;32m    315\u001b[0m niimg \u001b[38;5;241m=\u001b[39m load_niimg(niimg, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/nilearn/image/image.py:1488\u001b[0m, in \u001b[0;36mconcat_imgs\u001b[0;34m(niimgs, dtype, ensure_ndim, memory, memory_level, auto_resample, verbose)\u001b[0m\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m niimg \u001b[38;5;129;01min\u001b[39;00m literator:\n\u001b[1;32m   1486\u001b[0m     \u001b[38;5;66;03m# We check the dimensionality of the niimg\u001b[39;00m\n\u001b[1;32m   1487\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1488\u001b[0m         niimg \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_niimg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mniimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1489\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m DimensionError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m   1490\u001b[0m         \u001b[38;5;66;03m# Keep track of the additional dimension in the error\u001b[39;00m\n\u001b[1;32m   1491\u001b[0m         exc\u001b[38;5;241m.\u001b[39mincrement_stack_counter()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/nilearn/_utils/niimg_conversions.py:328\u001b[0m, in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    325\u001b[0m     niimg \u001b[38;5;241m=\u001b[39m new_img_like(niimg, data, niimg\u001b[38;5;241m.\u001b[39maffine)\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(niimg\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m ensure_ndim:\n\u001b[0;32m--> 328\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DimensionError(\u001b[38;5;28mlen\u001b[39m(niimg\u001b[38;5;241m.\u001b[39mshape), ensure_ndim)\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_iterator:\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (_index_img(niimg, i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(niimg\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m]))\n",
      "\u001b[0;31mDimensionError\u001b[0m: Input data has incompatible dimensionality: Expected dimension is 4D and you provided a list of 4D images (5D). See https://nilearn.github.io/stable/manipulating_images/input_output.html."
     ]
    }
   ],
   "source": [
    "#function to get first level weights for the runs\n",
    "#possible task types include colorWheel or sameDifferent \n",
    "\n",
    "def extract_beta_weights(subject_id = None, task_type = 'colorwheel',  n_runs=1):\n",
    "    \"\"\"\n",
    "    extract_beta_weights runs first level analysis on each of the subjects, \n",
    "    storing their weights for each task type and run in a dictionary.\n",
    "\n",
    "    subject_id: subject ID \n",
    "    task_type: colorWheel or sameDifferent \n",
    "    n_runs: max 4 runs, use less when testing\n",
    "    \"\"\"\n",
    "    #parameters\n",
    "    tr = 2.0 \n",
    "\n",
    "    # choose appropriate hrf model\n",
    "    hrf_model = \"spm + derivative\"\n",
    "    smoothing_fwhm = 6 # gaussian kernel width (in mm)\n",
    "    drift_model = None  # cosine drift terms already in confounds\n",
    "    high_pass=None,  # drift terms equivalent to high-pass filter\n",
    "    n_jobs=-2,  # use all-1 available CPUs\n",
    "\n",
    "    # choose whatever confounds you want to include\n",
    "    interested_confounds = [\"rot_x\", \"trans_x\", \"white_matter\", \"csf\"]\n",
    "\n",
    "    for num_run in range(n_runs):\n",
    "        preproc_path = f\"~/teams/a05/group_1_data/fmriprep/sub-{subject_id}/func/sub-{subject_id}_task-{task_type}**{num_run + 1}**desc-preproc_bold.nii.gz\"\n",
    "        events_path = f\"~/teams/a05/group_1_data/fmriprep/events/sub-{subject_id}_task-{task_type}_acq-multiband_run-{num_run+1}_events.tsv\"\n",
    "        \n",
    "        #load subject nii files\n",
    "        run_img = image.load_img(preproc_path)\n",
    "\n",
    "        #load the event file for the run\n",
    "        events = pd.read_csv(events_path, sep=\"\\t\", \n",
    "                            usecols=[\"onset\", \"duration\"]).assign(\n",
    "                            trial_type=\"colorwheel\")\n",
    "\n",
    "        #include confounds\n",
    "        confounds = interfaces.fmriprep.load_confounds_strategy(\n",
    "            preproc_path, denoise_strategy=\"simple\")[0]#[interested_confounds]\n",
    "\n",
    "        #run the first level model\n",
    "        fmri_glm = FirstLevelModel(\n",
    "            t_r=tr,\n",
    "            hrf_model=hrf_model,\n",
    "            smoothing_fwhm=smoothing_fwhm,\n",
    "            drift_model=drift_model,\n",
    "            minimize_memory=False   \n",
    "        )\n",
    "\n",
    "        fmri_glm = fmri_glm.fit(run_img, events, confounds)\n",
    "\n",
    "        #design matrix = task (convolved with HRF) + confounds\n",
    "        design_matrix = fmri_glm.design_matrices_[0]\n",
    "\n",
    "        # map of parameter estimates / beta weights\n",
    "        # this is the 'feature' map to use in classification\n",
    "        beta_weights = fmri_glm.compute_contrast(task_type, output_type=\"effect_size\")\n",
    "    return beta_weights\n",
    "\n",
    "extract_beta_weights(103, 'samedifferent')['samedifferent']['run_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # SVM classifier\n",
    "    svm_model = SVC(kernel='linear')\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "\n",
    "    # Evaluate performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Model Accuracy: \" + str(accuracy))\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    show()\n",
    "\n",
    "    return svm_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
